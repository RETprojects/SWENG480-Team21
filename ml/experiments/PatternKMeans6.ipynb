{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This notebook analyzes the efficacy of different clustering algorithms for matching design patterns and design problems.\n",
        "# Note: Table C2 in Hussain et al 2017 seems to indicate that fuzzy c-means clustering with binary weighting is the most effective combination for GoF patterns,\n",
        "# but TF-IDF yields the highest f-value for fuzzy c-means (0.73).\n",
        "# We are aiming for an f-value of 0.7 or above.\n",
        "\n",
        "!pip install unidecode\n",
        "!pip install fuzzy-c-means\n",
        "!pip install --upgrade scikit-learn\n",
        "!pip install scikit-learn-extra\n",
        "\n",
        "from fcmeans                          import FCM\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Data Structures\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import json\n",
        "# Corpus Processing\n",
        "import re\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "from nltk.tokenize                    import word_tokenize\n",
        "from nltk.stem                        import WordNetLemmatizer\n",
        "from nltk                             import SnowballStemmer, PorterStemmer\n",
        "from nltk.tag                         import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "from sklearn.feature_extraction.text  import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing            import normalize, Normalizer\n",
        "from sklearn.decomposition            import PCA, TruncatedSVD\n",
        "from sklearn.cluster                  import KMeans, BisectingKMeans, AgglomerativeClustering #, OPTICS\n",
        "from sklearn_extra.cluster            import KMedoids\n",
        "from sklearn.pipeline                 import make_pipeline\n",
        "\n",
        "from unidecode                        import unidecode\n",
        "\n",
        "# K-Means\n",
        "from sklearn                          import cluster\n",
        "\n",
        "# Visualization and Analysis\n",
        "import matplotlib.pyplot  as plt\n",
        "import matplotlib.cm      as cm\n",
        "import seaborn            as sns\n",
        "from sklearn.metrics                  import silhouette_samples, silhouette_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "from wordcloud                        import WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "lz6NJ12FIiXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f01c35a-aacd-460f-a650-f7ed277dc38c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzy-c-means\n",
            "  Downloading fuzzy_c_means-1.7.0-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from fuzzy-c-means) (1.10.7)\n",
            "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from fuzzy-c-means) (0.8.10)\n",
            "Collecting joblib<2.0.0,>=1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.4.0\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from fuzzy-c-means) (4.65.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from fuzzy-c-means) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2.0.0,>=1.9.0->fuzzy-c-means) (4.5.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.4.0->fuzzy-c-means) (8.1.3)\n",
            "Installing collected packages: typer, joblib, fuzzy-c-means\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.1\n",
            "    Uninstalling joblib-1.1.1:\n",
            "      Successfully uninstalled joblib-1.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fuzzy-c-means-1.7.0 joblib-1.2.0 typer-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn-extra\n",
            "  Downloading scikit_learn_extra-0.3.0-cp39-cp39-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn-extra) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn-extra) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn-extra) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.2.0)\n",
            "Installing collected packages: scikit-learn-extra\n",
            "Successfully installed scikit-learn-extra-0.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def getTrainData(fileName):\n",
        "  df = pd.read_csv(fileName)\n",
        "  df = df.drop_duplicates(subset=['name'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "ijpPxbCoPFKa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the design problem to the dataset.\n",
        "problemRow = {'name':\"bridge design problem 1\", 'correct_category':1, 'overview':\"Design a system enabling to display on a screen some empty windows (no button, no menu…). A window can have several different styles depending on the platform used. We consider two platforms, XWindow and Presentation Manager. The client code must be written independently and without knowledge of the future execution platform. It is probable that the system evolves in order to display specialized windows by ‘application windows’ (able to manage applications) and ‘iconised windows’ (with an icon)\"}\n",
        "problemRow2 = {'name':\"state design problem 2\", 'correct_category':0,  'overview':\"Design a DVD market place work. The DVD marketplace provides DVD to its clients with three categories: children, normal and new. A DVD is new during some weeks, and after change category. The DVD price depends on the category. It is probable that the system evolves in order to take into account the horror category\"}\n",
        "problemRow3 = {'name':\"mediator design problem 3\", 'correct_category':0,  'overview':\"Design the communications of a plane approaching an airport. When a plane approaches an airport, it must announce to all the other planes which are around that it intends to land, and await their confirmation before carrying out the operation. It is the control tower of the airport which guarantees the regulation of the air traffic, by making sure that there is no trajectory or destination conflict between several planes. In addition to the class diagram, you must also submit a collaboration (in the form of a diagram of collaboration or a diagram of objects and sequence) that describes the landing of a plane amidst in a context of two demands to land and one wanting to take off\"}\n",
        "problemRow4 = {'name':\"composite design problem 4\", 'correct_category':1, 'overview':\"Design a system enabling you to draw a graphic image. A graphic image is composed of lines, rectangles, texts, and images. An image may be composed of other images, lines, rectangles, and texts\"}\n",
        "problemRow5 = {'name':\"decorator design problem 5\", 'correct_category':1, 'overview':\"Design a system enabling you to display visual objects on a screen. A visual object can be composed of one or more texts or images. If needed, the system must allow the addition of a vertical scroll bar, a horizontal scroll bar, an edge and a menu to this object. These additions may be accumulated.\"}\n",
        "problemRow6 = {'name':\"chain of responsbility design problem 6\", 'correct_category':0, 'overview':\"Design a help manager for a Java application. A help manager allows the display of a help message depending on the objects on which a client has clicked. For example, the “?”, sometimes located near the contextual menu of a Windows dialog box, allows the display of the help related to the button or the area where to click. If the button on which one clicks does not contain help, it is the area container which displays its help, and so on. If any object contains help, the help manager displays /“No help available for this area/”. Instantiate your class diagram in a sequence diagram of the example of a printing window. This window (JDialog) consists in an explanatory text (JLabel) and in a container (JPanel). This last contains a /“Print button/” (JButton) and a /“Cancel button/” (JButton). The /“Print button/” contains help /“Launches the impression of the document/”. The /“Cancel button/” the text as well as the window do not contain help. Lastly, the container contains help /“Click on one of the buttons/”. In the sequence diagram, reveal the scenarios: /“The user asks for the help of the Print button/”, /“the user asks for the help of the Cancel button/”, and /“the user asks for the help of the text/”\"}\n",
        "problemRow7 = {'name':\"command design problem 7\", 'correct_category':0, 'overview':\"Design a tutorial to learn how to program a calculator. This calculator executes the four basic arithmetic operations. The goal of this tutorial is to make it possible to take a set of operations to be executed sequentially. The tutorial presents a button for each arithmetic operation, and two input fields for the operands. After each click on a button of an operation, the user has then the choice to start again or execute the sequence of operations to obtain the result. It is probable that this tutorial evolves in order to make it possible for the user to remove the last operation of the list and to take into account the operation of modulo\"}\n",
        "problemRow8 = {'name':\"visitor design problem 8\", 'correct_category':0, 'overview':\"Many distinct and unrelated operations need to be performed on node objects in a heterogeneous aggregate structure. You want to avoid ‘polluting’ the node classes with these operations. And, you don't want to have to query the type of each node and cast the pointer to the correct type before performing the desired operation.\"}\n",
        "problemRow9 = {'name':\"adapter design problem 9\", 'correct_category':1, 'overview':\"Design a drawing editor. A design is composed of te graphics (lines, rectangles and roses), positioned at precise positions. Each graphic form must be modeled by a class that provides a method draw(): void. A rose is a complex graphic designed by a black-box class component. This component performs this drawing in memory, and provides access through a method getRose(): int that returns the address of the drawing. It is probable that the system evolves in order to draw circles\"}\n",
        "#TODO: we need some design problems related to creational patterns\n",
        "#df = df.append(problemRow, ignore_index=True)\n",
        "df_problems = pd.DataFrame()\n",
        "df_problems = df_problems.append(problemRow2, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow3, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow4, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow5, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow6, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow7, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow8, ignore_index=True)\n",
        "df_problems = df_problems.append(problemRow9, ignore_index=True)\n",
        "df_problems"
      ],
      "metadata": {
        "id": "YmdAtfnSxdoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "291f4517-fe00-41e4-eda4-99b779511daf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      name  correct_category  \\\n",
              "0                   state design problem 2                 0   \n",
              "1                mediator design problem 3                 0   \n",
              "2               composite design problem 4                 1   \n",
              "3               decorator design problem 5                 1   \n",
              "4  chain of responsbility design problem 6                 0   \n",
              "5                 command design problem 7                 0   \n",
              "6                 visitor design problem 8                 0   \n",
              "7                 adapter design problem 9                 1   \n",
              "\n",
              "                                            overview  \n",
              "0  Design a DVD market place work. The DVD market...  \n",
              "1  Design the communications of a plane approachi...  \n",
              "2  Design a system enabling you to draw a graphic...  \n",
              "3  Design a system enabling you to display visual...  \n",
              "4  Design a help manager for a Java application. ...  \n",
              "5  Design a tutorial to learn how to program a ca...  \n",
              "6  Many distinct and unrelated operations need to...  \n",
              "7  Design a drawing editor. A design is composed ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a44283e-f145-4c8e-b8f6-360048942c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>correct_category</th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>state design problem 2</td>\n",
              "      <td>0</td>\n",
              "      <td>Design a DVD market place work. The DVD market...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mediator design problem 3</td>\n",
              "      <td>0</td>\n",
              "      <td>Design the communications of a plane approachi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>composite design problem 4</td>\n",
              "      <td>1</td>\n",
              "      <td>Design a system enabling you to draw a graphic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>decorator design problem 5</td>\n",
              "      <td>1</td>\n",
              "      <td>Design a system enabling you to display visual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chain of responsbility design problem 6</td>\n",
              "      <td>0</td>\n",
              "      <td>Design a help manager for a Java application. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>command design problem 7</td>\n",
              "      <td>0</td>\n",
              "      <td>Design a tutorial to learn how to program a ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>visitor design problem 8</td>\n",
              "      <td>0</td>\n",
              "      <td>Many distinct and unrelated operations need to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>adapter design problem 9</td>\n",
              "      <td>1</td>\n",
              "      <td>Design a drawing editor. A design is composed ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a44283e-f145-4c8e-b8f6-360048942c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a44283e-f145-4c8e-b8f6-360048942c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a44283e-f145-4c8e-b8f6-360048942c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a list of words (ie. stopwords) from a tokenized list.\n",
        "def removeWords(listOfTokens, listOfWords):\n",
        "    return [token for token in listOfTokens if token not in listOfWords]\n",
        "\n",
        "# applies stemming to a list of tokenized words\n",
        "def applyStemming(listOfTokens, stemmer):\n",
        "    return [stemmer.stem(token) for token in listOfTokens]\n",
        "\n",
        "# applied lemmatization to a list of tokenized words\n",
        "def applyLemmatization(listOfTokens, lemmatizer):\n",
        "    return [lemmatizer.lemmatize(token) for token in listOfTokens]\n",
        "\n",
        "# removes any words composed of less than 2 or more than 21 letters\n",
        "def twoLetters(listOfTokens):\n",
        "    twoLetterWord = []\n",
        "    for token in listOfTokens:\n",
        "        if len(token) <= 2 or len(token) >= 21:\n",
        "            twoLetterWord.append(token)\n",
        "    return twoLetterWord\n",
        "\n",
        "# removes any words that aren't verbs\n",
        "def notVerbs(listOfTokens):\n",
        "    notVerb = []\n",
        "    for token in listOfTokens:\n",
        "        if ( pos_tag(word_tokenize(token), tagset=\"universal\")[0][1] != \"VERB\" and pos_tag(word_tokenize(token), tagset=\"universal\")[0][1] != \"ADJ\" ):\n",
        "            notVerb.append(token)\n",
        "    return notVerb"
      ],
      "metadata": {
        "id": "WCyzW6A8Ic3D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processCorpus(corpus, language, stemmer, lemmatizer):   \n",
        "    stopwords = nltk.corpus.stopwords.words(language)\n",
        "    param_stemmer = stemmer\n",
        "    \n",
        "    for document in corpus:\n",
        "        index = corpus.index(document)\n",
        "        corpus[index] = str(corpus[index]).replace(u'\\ufffd', '8')   # Replaces the ASCII '�' symbol with '8'\n",
        "        corpus[index] = corpus[index].replace(',', '')          # Removes commas\n",
        "        corpus[index] = corpus[index].rstrip('\\n')              # Removes line breaks\n",
        "        corpus[index] = corpus[index].casefold()                # Makes all letters lowercase\n",
        "        \n",
        "        corpus[index] = re.sub('\\W_',' ', corpus[index])        # removes specials characters and leaves only words\n",
        "        corpus[index] = re.sub(\"\\S*\\d\\S*\",\" \", corpus[index])   # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.\n",
        "        corpus[index] = re.sub(\"\\S*@\\S*\\s?\",\" \", corpus[index]) # removes emails and mentions (words with @)\n",
        "        corpus[index] = re.sub(r'http\\S+', '', corpus[index])   # removes URLs with http\n",
        "        corpus[index] = re.sub(r'www\\S+', '', corpus[index])    # removes URLs with www\n",
        "\n",
        "        listOfTokens = word_tokenize(corpus[index])\n",
        "        twoLetterWord = twoLetters(listOfTokens)\n",
        "        notVerb = notVerbs(listOfTokens)\n",
        "\n",
        "        listOfTokens = removeWords(listOfTokens, stopwords)\n",
        "        listOfTokens = removeWords(listOfTokens, twoLetterWord)\n",
        "        listOfTokens = removeWords(listOfTokens, notVerb)\n",
        "        \n",
        "        listOfTokens = applyStemming(listOfTokens, param_stemmer)\n",
        "        #listOfTokens = applyLemmatization(listOfTokens, lemmatizer)\n",
        "\n",
        "        corpus[index]   = \" \".join(listOfTokens)\n",
        "        corpus[index] = unidecode(corpus[index])\n",
        "\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "gNyvdEQ-IsoQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: use k-means before this chunk of code to classify the problem with a pattern class, then perform cosine similarity with the problem and the list of candidate patterns from that class.\n",
        "# Source: https://danielcaraway.github.io/html/sklearn_cosine_similarity.html\n",
        "\n",
        "def cosine_sim(df, df_col, class_no, pos_to_last, predicted_labels):\n",
        "  unigram_count = CountVectorizer(encoding='latin-1', binary=False)\n",
        "  unigram_count_stop_remove = CountVectorizer(encoding='latin-1', binary=False, stop_words='english')\n",
        "\n",
        "  # get the list of candidate patterns\n",
        "  txts = df_col.loc[predicted_labels == class_no] # where label == class_no\n",
        "  vecs = unigram_count.fit_transform(txts)\n",
        "  \n",
        "  cos_sim = cosine_similarity(vecs[-pos_to_last], vecs)\n",
        "  #sim_sorted_doc_idx = cos_sim.argsort()\n",
        "  # print the most similar pattern to the problem; it's actually the problem itself\n",
        "  #print(\"Design Problem: \\n\" + txts.iloc[sim_sorted_doc_idx[-1][len(txts)-1]] + \"\\n\")\n",
        "\n",
        "  #bestFittingPatternDesc = txts.iloc[sim_sorted_doc_idx[-1][len(txts)-2]]\n",
        "\n",
        "  # print the second most similar pattern; it's likely the best-fitting design pattern for the design problem\n",
        "  #print(txts[sim_sorted_doc_idx[-1][len(txts)-2]])\n",
        "  #print(\"\\nCorrect Pattern: \" + (df['name'][(df['overview'] == bestFittingPatternDesc)]).to_string(index=False) + \"\\n\")\n",
        "\n",
        "  return cos_sim, txts\n"
      ],
      "metadata": {
        "id": "98Wc23fugsBk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def displayPredictions(cos_sim, txts, df):\n",
        "  sim_sorted_doc_idx = cos_sim.argsort()\n",
        "  for i in range(len(txts) - 1):\n",
        "    patternDesc = txts.iloc[sim_sorted_doc_idx[-1][len(txts)-(i + 2)]]\n",
        "    patternName = (df['name'][(df['overview'] == patternDesc)]).to_string(index=False)\n",
        "    percentMatch = int((cos_sim[0][sim_sorted_doc_idx[-1][len(txts)-(i + 2)]]) * 100)\n",
        "    print(\"{}th pattern:  {:<20}{}%  match\".format(i+1, patternName, percentMatch))\n"
      ],
      "metadata": {
        "id": "M-VWv1XhUvQm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def runAlgorithms(num_clusters, final_df, df):\n",
        "#   # bisecting_strategy{“biggest_inertia”, “largest_cluster”}, default=”biggest_inertia”\n",
        "#   final_df_array = final_df.to_numpy()\n",
        "\n",
        "#   Bi_Bisect = BisectingKMeans(n_clusters=num_clusters, bisecting_strategy=\"biggest_inertia\")\n",
        "#   Lc_Bisect = BisectingKMeans(n_clusters=num_clusters, bisecting_strategy=\"largest_cluster\")\n",
        "#   Hierarchy = AgglomerativeClustering(n_clusters=num_clusters)\n",
        "#   Fuzzy_Means = FCM(n_clusters=num_clusters)\n",
        "#   Fuzzy_Means.fit(final_df_array)\n",
        "#   kmed = KMedoids(n_clusters=num_clusters)\n",
        "#   kmed_manhattan = KMedoids(n_clusters=num_clusters,metric='manhattan')\n",
        "#   Kmeans = cluster.KMeans(n_clusters = num_clusters)\n",
        "#   # optics = cluster.OPTICS(min_samples=num_clusters)\n",
        "\n",
        "#   Kmeans_labels = Kmeans.fit_predict(final_df)\n",
        "#   fuzzy_labels = Fuzzy_Means.predict(final_df_array)\n",
        "#   bi_bisect_labels = Bi_Bisect.fit_predict(final_df)\n",
        "#   lc_bisect_labels = Lc_Bisect.fit_predict(final_df)  \n",
        "#   hierarchy_labels = Hierarchy.fit_predict(final_df)\n",
        "#   kmed_labels = kmed.fit_predict(final_df)\n",
        "#   kmed_man_labels = kmed_manhattan.fit_predict(final_df)\n",
        "#   # optics_labels = optics.fit_predict(final_df_array)\n",
        "\n",
        "#   df['Kmeans'] = Kmeans_labels\n",
        "#   df['fuzzy'] = fuzzy_labels\n",
        "#   df['hierarchy'] = hierarchy_labels\n",
        "#   df['Bi_Bisect'] = bi_bisect_labels  \n",
        "#   df['Lc_Bisect'] = lc_bisect_labels\n",
        "#   df['PAM-EUCLIDEAN'] = kmed_labels\n",
        "#   df['PAM-MANHATTAN'] = kmed_man_labels\n",
        "#   # df['OPTICS'] = optics_labels\n"
      ],
      "metadata": {
        "id": "zhxsGG5oQ-M0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Silhouette(vector_data, cluster_labels):\n",
        "  # range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9]\n",
        "  #silhouette_avg = []\n",
        "  # for num_clusters in range_n_clusters:\n",
        "  #   # initialise kmeans\n",
        "  #   kmeans = KMeans(n_clusters=num_clusters, n_init='auto')\n",
        "  #   kmeans.fit(vector_data)\n",
        "  #   cluster_labels = kmeans.labels_\n",
        "    \n",
        "    # silhouette score\n",
        "    #silhouette_avg.append(silhouette_score(vector_data, cluster_labels))\n",
        "  s_avg = silhouette_score(vector_data, cluster_labels)\n",
        "  return s_avg\n",
        "  # plt.plot(range_n_clusters,silhouette_avg,'bx-')\n",
        "\n",
        "  # plt.xlabel('Values of K') \n",
        "  # plt.ylabel('Silhouette score') \n",
        "  # plt.title('Silhouette analysis For Optimal k')\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "VmG-CDTwX9fQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFScore(labels, df):\n",
        "  df2 = df.pivot_table(index = ['correct_category'], aggfunc ='size')\n",
        "\n",
        "  num_of_creational = df2[2]\n",
        "  num_of_structural = df2[1]\n",
        "  num_of_behavioral = df2[0]\n",
        "\n",
        "  true_1 = [0]*num_of_creational + [1]*num_of_structural + [2]*num_of_behavioral\n",
        "  true_2 = [0]*num_of_creational + [2]*num_of_structural + [1]*num_of_behavioral\n",
        "  true_3 = [1]*num_of_creational + [0]*num_of_structural + [2]*num_of_behavioral\n",
        "  true_4 = [1]*num_of_creational + [2]*num_of_structural + [0]*num_of_behavioral\n",
        "  true_5 = [2]*num_of_creational + [0]*num_of_structural + [1]*num_of_behavioral\n",
        "  true_6 = [2]*num_of_creational + [1]*num_of_structural + [0]*num_of_behavioral\n",
        "\n",
        "  #print('===========KMEANS===========')\n",
        "  #print('Predicted labels:')\n",
        "  #display(Kmeans_labels.tolist())\n",
        "\n",
        "  fscores = [\n",
        "      f1_score(true_1, labels.tolist(),average='micro'),\n",
        "      f1_score(true_2, labels.tolist(),average='micro'),\n",
        "      f1_score(true_3, labels.tolist(),average='micro'),\n",
        "      f1_score(true_4, labels.tolist(),average='micro'),\n",
        "      f1_score(true_5, labels.tolist(),average='micro'),\n",
        "      f1_score(true_6, labels.tolist(),average='micro')\n",
        "  ]\n",
        "\n",
        "  km_best = np.around(max(fscores),3)\n",
        "  #print('\\nBest fscore is:', km_best, 'from true_' + str(np.argmax(fscores) + 1))\n",
        "  #display(globals()['true_' + str(np.argmax(fscores) + 1)])\n",
        "  return km_best"
      ],
      "metadata": {
        "id": "fNjONkNy41dS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def validateInput(designProblem):\n",
        "#   numOfWords = len(designProblem.split())\n",
        "#   if (numOfWords < 30 or numOfWords > 120):\n",
        "#     return False\n",
        "#   return True\n",
        "\n",
        "# def main():\n",
        "#   language = 'english'\n",
        "#   stemmer = PorterStemmer()\n",
        "#   lemmatizer = WordNetLemmatizer()\n",
        "#   vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
        "#   df = getTrainData(\"GOF Patterns (2.0).csv\")\n",
        "\n",
        "#   while(True):\n",
        "#     # designProblem = input(\"Enter your design problem: \\n\")\n",
        "\n",
        "#     # if(not validateInput(designProblem)):\n",
        "#     #   print(\"Invalid input size! please try again. \\n\")\n",
        "#     #   continue\n",
        "\n",
        "#     # problemRow = {'name':\"design problem\", 'correct_category':4, 'overview': designProblem}\n",
        "#     # df = df.append(problemRow, ignore_index=True)\n",
        "\n",
        "#     corpus = df['overview'].tolist()\n",
        "#     corpus = processCorpus(corpus, language, stemmer, lemmatizer)\n",
        "\n",
        "#     print(corpus[12][0:270])\n",
        "\n",
        "#     X = vectorizer.fit_transform(corpus)\n",
        "#     tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "#     #runAlgorithms(3, tf_idf, df)\n",
        "#     #cos_sim, txts = cosine_sim(df, df['overview'], df['Kmeans'].iloc[df.index[-1]], 1)\n",
        "#     #displayPredictions(cos_sim, txts, df)\n",
        "#     return df, tf_idf, #cos_sim, txts \n",
        "\n",
        "# #df, cos_sim, txts, tfidf = main()\n",
        "# df, tfidf = main()\n"
      ],
      "metadata": {
        "id": "XkshK0w6W7vm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kmeans_silhouette_avg = []\n",
        "# kmeans_fscore_avg = []\n",
        "\n",
        "# fmeans_silhouette_avg = []\n",
        "# fmeans_fscore_avg = []\n",
        "\n",
        "# hier_silhouette_avg = []\n",
        "# hier_fscore_avg = []\n",
        "\n",
        "# # kmed_silhouette_avg = []\n",
        "# # kmed_fscore_avg = []\n",
        "\n",
        "# # kmed_man_silhouette_avg = []\n",
        "# # kmed_man_fscore_avg = []\n",
        "\n",
        "# # bi_bisect_silhouette_avg = []\n",
        "# # bi_bisect_fscore_avg = []\n",
        "\n",
        "# # lc_bisect_silhouette_avg = []\n",
        "# # lc_bisect_fscore_avg = []\n",
        "\n",
        "# # optics_silhouette_avg = []\n",
        "# # optics_fscore_avg = []\n",
        "\n",
        "# num_clusters = 3\n",
        "# final_df = tfidf\n",
        "# final_df_array = final_df.to_numpy()\n",
        "\n",
        "# Hierarchy = AgglomerativeClustering(n_clusters=num_clusters)\n",
        "# Fuzzy_Means = FCM(n_clusters=num_clusters, m=1.67, max_iter=270)\n",
        "# Kmeans = cluster.KMeans(n_clusters = num_clusters, n_init='auto', max_iter=339, tol=0.0001)\n",
        "# # Bi_Bisect = BisectingKMeans(n_clusters=num_clusters, bisecting_strategy=\"biggest_inertia\")\n",
        "# # Lc_Bisect = BisectingKMeans(n_clusters=num_clusters, bisecting_strategy=\"largest_cluster\")\n",
        "# # kmed = KMedoids(n_clusters=num_clusters)\n",
        "# # kmed_manhattan = KMedoids(n_clusters=num_clusters,metric='manhattan')\n",
        "# # optics = cluster.OPTICS(min_samples=num_clusters)\n",
        "\n",
        "# for i in range(40):\n",
        "#     Fuzzy_Means.fit(final_df_array)\n",
        "#     Kmeans_labels = Kmeans.fit_predict(final_df)\n",
        "#     fuzzy_labels = Fuzzy_Means.predict(final_df_array)\n",
        "#     hierarchy_labels = Hierarchy.fit_predict(final_df)\n",
        "#     # bi_bisect_labels = Bi_Bisect.fit_predict(final_df)\n",
        "#     # lc_bisect_labels = Lc_Bisect.fit_predict(final_df)  \n",
        "#     # kmed_labels = kmed.fit_predict(final_df)\n",
        "#     # kmed_man_labels = kmed_manhattan.fit_predict(final_df)\n",
        "#     # optics_labels = optics.fit_predict(final_df_array)\n",
        "\n",
        "#     kmeans_fscore_avg.append(getFScore(Kmeans_labels, df))\n",
        "#     kmeans_silhouette_avg.append(Silhouette(tfidf, Kmeans_labels))\n",
        "\n",
        "#     fmeans_fscore_avg.append(getFScore(fuzzy_labels, df))\n",
        "#     fmeans_silhouette_avg.append(Silhouette(tfidf, fuzzy_labels))\n",
        "\n",
        "#     hier_fscore_avg.append(getFScore(hierarchy_labels, df))\n",
        "#     hier_silhouette_avg.append(Silhouette(tfidf, hierarchy_labels))\n",
        "\n",
        "#     # kmed_fscore_avg.append(getFScore(kmed_labels, df))\n",
        "#     # kmed_silhouette_avg.append(Silhouette(tfidf, kmed_labels))\n",
        "\n",
        "#     # kmed_man_fscore_avg.append(getFScore(kmed_man_labels, df))\n",
        "#     # kmed_man_silhouette_avg.append(Silhouette(tfidf, kmed_man_labels))\n",
        "\n",
        "#     # bi_bisect_fscore_avg.append(getFScore(bi_bisect_labels, df))\n",
        "#     # bi_bisect_silhouette_avg.append(Silhouette(tfidf, bi_bisect_labels))\n",
        "\n",
        "#     # lc_bisect_fscore_avg.append(getFScore(lc_bisect_labels, df))\n",
        "#     # lc_bisect_silhouette_avg.append(Silhouette(tfidf, lc_bisect_labels))\n",
        "\n",
        "#     # optics_fscore_avg.append(getFScore(optics_labels, df))\n",
        "#     # optics_silhouette_avg.append(Silhouette(tfidf, optics_labels))\n",
        "\n",
        "#     print(fuzzy_labels)\n",
        "\n",
        "# print(\"\\n===========kmeans===========\\n\")\n",
        "# print(\"Average f-score:           \", sum(kmeans_fscore_avg) / len(kmeans_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(kmeans_silhouette_avg) / len(kmeans_silhouette_avg))\n",
        "\n",
        "# print(\"\\n===========fmeans===========\\n\")\n",
        "# print(\"Average f-score:           \", sum(fmeans_fscore_avg) / len(fmeans_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(fmeans_silhouette_avg) / len(fmeans_silhouette_avg))\n",
        "\n",
        "# print(\"\\n=========hierarchy==========\\n\")\n",
        "# print(\"Average f-score:           \", sum(hier_fscore_avg) / len(hier_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(hier_silhouette_avg) / len(hier_silhouette_avg))\n",
        "\n",
        "# print(\"\\n============kmed============\\n\")\n",
        "# print(\"Average f-score:           \", sum(kmed_fscore_avg) / len(kmed_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(kmed_silhouette_avg) / len(kmed_silhouette_avg))\n",
        "\n",
        "# print(\"\\n==========kmed-man==========\\n\")\n",
        "# print(\"Average f-score:           \", sum(kmed_man_fscore_avg) / len(kmed_man_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(kmed_man_silhouette_avg) / len(kmed_man_silhouette_avg))\n",
        "\n",
        "# print(\"\\n=========bi-bisect==========\\n\")\n",
        "# print(\"Average f-score:           \", sum(bi_bisect_fscore_avg) / len(bi_bisect_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(bi_bisect_silhouette_avg) / len(bi_bisect_silhouette_avg))\n",
        "\n",
        "# print(\"\\n=========lc-bisect==========\\n\")\n",
        "# print(\"Average f-score:           \", sum(lc_bisect_fscore_avg) / len(lc_bisect_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(lc_bisect_silhouette_avg) / len(lc_bisect_silhouette_avg))\n",
        "\n",
        "# print(\"\\n===========optics===========\\n\")\n",
        "# print(\"Average f-score:           \", sum(optics_fscore_avg) / len(optics_fscore_avg))\n",
        "# print(\"Average silhouette score:  \", sum(optics_silhouette_avg) / len(optics_silhouette_avg))"
      ],
      "metadata": {
        "id": "uFZP-jwwhBXv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TestDesignProblems():\n",
        "  language = 'english'\n",
        "  stemmer = PorterStemmer()\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
        "  df_test = getTrainData(\"GOF Patterns (2.0).csv\")\n",
        "\n",
        "  num_clusters = 3\n",
        "  Fuzzy_Means = FCM(n_clusters=num_clusters, m=1.67, max_iter=270)\n",
        "\n",
        "  while(True):\n",
        "    for i in range(len(df_problems)):\n",
        "      # display design problem\n",
        "      print(\"Design Problem \", i, \": \", df_problems['name'].iloc[i])\n",
        "\n",
        "      # add design problem\n",
        "      df_test = df_test.append(df_problems.iloc[i], ignore_index=True)\n",
        "\n",
        "      # pre process\n",
        "      corpus = df_test['overview'].tolist()\n",
        "      corpus = processCorpus(corpus, language, stemmer, lemmatizer)\n",
        "\n",
        "      # vectorize data\n",
        "      X = vectorizer.fit_transform(corpus)\n",
        "      tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "      final_df = tf_idf\n",
        "      final_df_array = final_df.to_numpy()\n",
        "\n",
        "      # run model\n",
        "      Fuzzy_Means.fit(final_df_array)\n",
        "      fuzzy_labels = Fuzzy_Means.predict(final_df_array)\n",
        "      df_test['Fmeans'] = fuzzy_labels\n",
        "      \n",
        "      # cosine similarity\n",
        "      cos_sim, txts = cosine_sim(df_test, df_test['overview'], df_test['Fmeans'].iloc[df_test.index[-1]], 1, df_test['Fmeans'])\n",
        "      displayPredictions(cos_sim, txts, df_test)\n",
        "\n",
        "      # clean up\n",
        "\n",
        "      n = df_test.index[-1]\n",
        "      problemRow = df_test.iloc[[n]]\n",
        "      # Using drop() function to delete last row\n",
        "      df_test.drop(index=n,axis=0,inplace=True)\n",
        "      df_test.drop(['Fmeans'], axis=1)\n",
        "\n",
        "    return df_test, tf_idf, #cos_sim, txts \n",
        "\n",
        "#df, cos_sim, txts, tfidf = main()\n",
        "df_test, tfidf = TestDesignProblems()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13bjmyUMq7DG",
        "outputId": "480b416c-8d2f-43d3-fd68-c522de73c204"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Design Problem  0 :  state design problem 2\n",
            "1th pattern:  proxy               50%  match\n",
            "2th pattern:  adapter             48%  match\n",
            "3th pattern:  decorator           47%  match\n",
            "4th pattern:  facade              43%  match\n",
            "5th pattern:  singleton           41%  match\n",
            "6th pattern:  factory method      39%  match\n",
            "7th pattern:  prototype           35%  match\n",
            "Design Problem  1 :  mediator design problem 3\n",
            "1th pattern:  proxy               68%  match\n",
            "2th pattern:  decorator           68%  match\n",
            "3th pattern:  factory method      66%  match\n",
            "4th pattern:  abstract factory    64%  match\n",
            "5th pattern:  facade              61%  match\n",
            "6th pattern:  adapter             59%  match\n",
            "7th pattern:  singleton           58%  match\n",
            "8th pattern:  prototype           58%  match\n",
            "Design Problem  2 :  composite design problem 4\n",
            "1th pattern:  bridge              28%  match\n",
            "2th pattern:  abstract factory    27%  match\n",
            "3th pattern:  decorator           26%  match\n",
            "4th pattern:  flyweight           25%  match\n",
            "5th pattern:  factory method      24%  match\n",
            "6th pattern:  singleton           23%  match\n",
            "7th pattern:  prototype           22%  match\n",
            "8th pattern:  facade              20%  match\n",
            "9th pattern:  proxy               20%  match\n",
            "10th pattern:  adapter             18%  match\n",
            "Design Problem  3 :  decorator design problem 5\n",
            "1th pattern:  proxy               49%  match\n",
            "2th pattern:  command             48%  match\n",
            "3th pattern:  chain of responsibility46%  match\n",
            "4th pattern:  memento             45%  match\n",
            "5th pattern:  facade              37%  match\n",
            "Design Problem  4 :  chain of responsbility design problem 6\n",
            "1th pattern:  mediator            71%  match\n",
            "2th pattern:  flyweight           67%  match\n",
            "3th pattern:  observer            65%  match\n",
            "4th pattern:  visitor             65%  match\n",
            "5th pattern:  builder             62%  match\n",
            "6th pattern:  strategy            60%  match\n",
            "7th pattern:  template method     60%  match\n",
            "Design Problem  5 :  command design problem 7\n",
            "1th pattern:  proxy               72%  match\n",
            "2th pattern:  facade              65%  match\n",
            "3th pattern:  builder             61%  match\n",
            "4th pattern:  factory method      61%  match\n",
            "5th pattern:  singleton           58%  match\n",
            "6th pattern:  adapter             57%  match\n",
            "7th pattern:  prototype           54%  match\n",
            "Design Problem  6 :  visitor design problem 8\n",
            "1th pattern:  facade              55%  match\n",
            "2th pattern:  singleton           51%  match\n",
            "Design Problem  7 :  adapter design problem 9\n",
            "1th pattern:  template method     45%  match\n",
            "2th pattern:  flyweight           45%  match\n",
            "3th pattern:  interpreter         44%  match\n",
            "4th pattern:  memento             43%  match\n",
            "5th pattern:  observer            40%  match\n"
          ]
        }
      ]
    }
  ]
}